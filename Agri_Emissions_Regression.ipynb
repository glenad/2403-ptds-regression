{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8793c33",
   "metadata": {},
   "source": [
    "# Agricultural Emissions Regression Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5559f3f5",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "* <b>[1. Project Overview](#chapter1)\n",
    "* <b>[2. Importing Packages](#chapter2)\n",
    "* <b>[3. Loading Data](#chapter3)\n",
    "* <b>[4. Data Cleaning](#chapter4)\n",
    "* <b>[5. Exploratory Data Analysis (EDA)](#chapter5)\n",
    "* <b>[6. Regression Models](#chapter6)\n",
    "* <b>[7. Conclusion](#chapter7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a277b308",
   "metadata": {},
   "source": [
    "## 1. Project Overview <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b168c",
   "metadata": {},
   "source": [
    "The purpose of this project is to analyze the the dataset, which contains detailed information on Agruu emissions from 2015 to 20231. \n",
    "\n",
    "\n",
    "The primary goal is to identify trends and patterns in avocado pricing and sales across different regions and time periods. This analysis is significant as it can provide valuable insights for stakeholders such as farmers, retailers, and policymakers to make informed decisions. The project aims to address specific questions such as the factors influencing price fluctuations, seasonal variations in sales, and the impact of external events on the avocado market. By leveraging this comprehensive dataset, the project sets the stage for a deeper understanding of the avocado market, ultimately contributing to more efficient market strategies and improved supply chain management\n",
    "\n",
    "For our analysis we will employ  statistical techniques in section 5 Explority Data Analysis (EDA).\n",
    "\n",
    "The notebook is structured to guide readers through a comprehensive data analysis project. It begins with a Project Overview, which includes an Introduction outlining the context and a Problem Statement to define the issue at hand, followed by the Objectives of the analysis. Next, the Importing Packages section lists the necessary libraries. Loading Data details the process of importing datasets. Data Cleaning addresses how the data is prepared for analysis. The Exploratory Data Analysis (EDA) section provides insights into the data through visualizations and summary statistics. Feature Engineering involves creating new features to improve model performance. The Modeling section describes the algorithms used and their implementation. Model Performance evaluates the effectiveness of the models. The notebook also includes a section on Machine Learning Sprints for further learning, followed by a Conclusion summarizing the findings, and References for sourcing information. \n",
    "\n",
    "Through this project, we hope to provide a detailed understanding of the current state of the avocado market, identify challenges and opportunities, and propose actionable recommendations to enhance the efficiency and sustainability of avocado farming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22219f93",
   "metadata": {},
   "source": [
    "## 2. Importing Packages <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da21038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe0af2f",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#three></a>\n",
    "## **Loading Data**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Load the data into the notebook for manipulation and analysis.\n",
    "* **Details:** Show the code used to load the data and display the first few rows to give a sense of what the raw data looks like.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a0c54",
   "metadata": {},
   "source": [
    "## 3. Loading Data <a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ff67a4",
   "metadata": {},
   "source": [
    "<a href=#two></a>\n",
    "## **Data Collection and Description**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Describe how the data was collected and provide an overview of its characteristics.\n",
    "* **Details:** Mention sources of the data, the methods used for collection (e.g., APIs, web scraping, datasets from repositories), and a general description of the dataset including size, scope, and types of data available (e.g., numerical, categorical).\n",
    "---\n",
    "\n",
    "The dataset titled \"Avocado Prices and Sales Volume 2015-2023\" was collected from Kaggle, a well-known platform for data science and machine learning datasets¹. The data was gathered using various methods, including web scraping and APIs, to compile comprehensive information on avocado prices and sales volumes across multiple U.S. markets. This dataset spans from 2015 to 2023 and includes both numerical and categorical data. The numerical data covers aspects such as average prices, total volume, and type of avocado (conventional or organic), while the categorical data includes regions and dates. The dataset is extensive, providing a detailed view of market trends over an eight-year period¹.\n",
    "\n",
    "¹: [Kaggle - Avocado Prices and Sales Volume 2015-2023](https://www.kaggle.com/datasets/vakhariapujan/avocado-prices-and-sales-volume-2015-2023)\n",
    "\n",
    "Source: Conversation with Copilot, 2024/09/15\n",
    "(1) Avocado Prices and Sales Volume 2015-2023 - Kaggle. https://www.kaggle.com/datasets/vakhariapujan/avocado-prices-and-sales-volume-2015-2023.\n",
    "(2) Kaggle: Your Home for Data Science. https://www.kaggle.com/datasets/vakhariapujan/avocado-prices-and-sales-volume-2015-2023/download?datasetVersionNumber=3.\n",
    "(3) The Price and Sales of Avocado - Kaggle. https://www.kaggle.com/datasets/alanluo418/avocado-prices-20152019.\n",
    "(4) undefined. https://www.kaggle.com/static/assets/app.js?v=ee89c9be8cfec5b47292:2:2059285.\n",
    "(5) undefined. https://www.kaggle.com/static/assets/app.js?v=ee89c9be8cfec5b47292:2:2056226.\n",
    "(6) undefined. https://www.kaggle.com/static/assets/app.js?v=ee89c9be8cfec5b47292:2:2056331%29.\n",
    "(7) undefined. https://www.kaggle.com/static/assets/app.js?v=ee89c9be8cfec5b47292:2:2054570%29.\n",
    "(8) undefined. https://www.kaggle.com/static/assets/app.js?v=ee89c9be8cfec5b47292:2:2054773%29."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9eefc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"co2_emissions_from_agri.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d643f7",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#four></a>\n",
    "## **Data Cleaning and Filtering**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Prepare the data for analysis by cleaning and filtering.\n",
    "* **Details:** Include steps for handling missing values, removing outliers, correcting errors, and possibly reducing the data (filtering based on certain criteria or features).\n",
    "---\n",
    "The Dataset contains 53415 rows of made up of :\n",
    "* 12 Columns of which:\n",
    "\n",
    "* 9 are float64 containing numerical data, of which\n",
    "* 9 are formatted with two decimal place\n",
    "* 2 are object, containing text - type and region\n",
    "* 1 is an object containing a date field\n",
    "\n",
    "From the above we conclude most of the data is numerical, with the type and region being categorical, and the date being categorical\n",
    "\n",
    "A check_for_null_values() function is used to display a count of null (missing / nan) values per column. It uses isnull() to return True for each null value found in the dataframe. The sum() function totals the number of these null values for each column. The columns and number of missing values are assigned to the missing_values Series object. The any() function is used to check if the missing_values series contains any values.\n",
    "\n",
    "The dataframe contains the following null values\n",
    "* SmallBags has 12390 null values\n",
    "* LargeBags has 12390 null values\n",
    "* XLargeBags has 12390 null values\n",
    "\n",
    "A count_duplicate_rows is used to check for duplicate rows. count_duplicate_row()` function returns True for each duplicated row found in the dataframe. The number of true values are summed and if duplicated rows exist the rows are displayed.\n",
    "\n",
    "The dataframe contains no duplicated rows.\n",
    "\n",
    "It was noted that all the float64 columns contained values = -1. It is good practice to replace the \"-1\" values with \"nan\" so that pandas can use statistical functions accurately on the columns.\n",
    "\n",
    "Number of Years: 9\n",
    "Min year: 2015\n",
    "Max year: 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e778cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6965 entries, 0 to 6964\n",
      "Data columns (total 31 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Area                             6965 non-null   object \n",
      " 1   Year                             6965 non-null   int64  \n",
      " 2   Savanna fires                    6934 non-null   float64\n",
      " 3   Forest fires                     6872 non-null   float64\n",
      " 4   Crop Residues                    5576 non-null   float64\n",
      " 5   Rice Cultivation                 6965 non-null   float64\n",
      " 6   Drained organic soils (CO2)      6965 non-null   float64\n",
      " 7   Pesticides Manufacturing         6965 non-null   float64\n",
      " 8   Food Transport                   6965 non-null   float64\n",
      " 9   Forestland                       6472 non-null   float64\n",
      " 10  Net Forest conversion            6472 non-null   float64\n",
      " 11  Food Household Consumption       6492 non-null   float64\n",
      " 12  Food Retail                      6965 non-null   float64\n",
      " 13  On-farm Electricity Use          6965 non-null   float64\n",
      " 14  Food Packaging                   6965 non-null   float64\n",
      " 15  Agrifood Systems Waste Disposal  6965 non-null   float64\n",
      " 16  Food Processing                  6965 non-null   float64\n",
      " 17  Fertilizers Manufacturing        6965 non-null   float64\n",
      " 18  IPPU                             6222 non-null   float64\n",
      " 19  Manure applied to Soils          6037 non-null   float64\n",
      " 20  Manure left on Pasture           6965 non-null   float64\n",
      " 21  Manure Management                6037 non-null   float64\n",
      " 22  Fires in organic soils           6965 non-null   float64\n",
      " 23  Fires in humid tropical forests  6810 non-null   float64\n",
      " 24  On-farm energy use               6009 non-null   float64\n",
      " 25  Rural population                 6965 non-null   float64\n",
      " 26  Urban population                 6965 non-null   float64\n",
      " 27  Total Population - Male          6965 non-null   float64\n",
      " 28  Total Population - Female        6965 non-null   float64\n",
      " 29  total_emission                   6965 non-null   float64\n",
      " 30  Average Temperature °C           6965 non-null   float64\n",
      "dtypes: float64(29), int64(1), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Year</th>\n",
       "      <th>Savanna fires</th>\n",
       "      <th>Forest fires</th>\n",
       "      <th>Crop Residues</th>\n",
       "      <th>Rice Cultivation</th>\n",
       "      <th>Drained organic soils (CO2)</th>\n",
       "      <th>Pesticides Manufacturing</th>\n",
       "      <th>Food Transport</th>\n",
       "      <th>Forestland</th>\n",
       "      <th>Net Forest conversion</th>\n",
       "      <th>Food Household Consumption</th>\n",
       "      <th>Food Retail</th>\n",
       "      <th>On-farm Electricity Use</th>\n",
       "      <th>Food Packaging</th>\n",
       "      <th>Agrifood Systems Waste Disposal</th>\n",
       "      <th>Food Processing</th>\n",
       "      <th>Fertilizers Manufacturing</th>\n",
       "      <th>IPPU</th>\n",
       "      <th>Manure applied to Soils</th>\n",
       "      <th>Manure left on Pasture</th>\n",
       "      <th>Manure Management</th>\n",
       "      <th>Fires in organic soils</th>\n",
       "      <th>Fires in humid tropical forests</th>\n",
       "      <th>On-farm energy use</th>\n",
       "      <th>Rural population</th>\n",
       "      <th>Urban population</th>\n",
       "      <th>Total Population - Male</th>\n",
       "      <th>Total Population - Female</th>\n",
       "      <th>total_emission</th>\n",
       "      <th>Average Temperature °C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1990</td>\n",
       "      <td>14.7237</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>205.6077</td>\n",
       "      <td>686.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.807483</td>\n",
       "      <td>63.1152</td>\n",
       "      <td>-2388.8030</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>79.0851</td>\n",
       "      <td>109.6446</td>\n",
       "      <td>14.2666</td>\n",
       "      <td>67.631366</td>\n",
       "      <td>691.7888</td>\n",
       "      <td>252.21419</td>\n",
       "      <td>11.997000</td>\n",
       "      <td>209.9778</td>\n",
       "      <td>260.1431</td>\n",
       "      <td>1590.5319</td>\n",
       "      <td>319.1763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9655167.0</td>\n",
       "      <td>2593947.0</td>\n",
       "      <td>5348387.0</td>\n",
       "      <td>5346409.0</td>\n",
       "      <td>2198.963539</td>\n",
       "      <td>0.536167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1991</td>\n",
       "      <td>14.7237</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>209.4971</td>\n",
       "      <td>678.1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.712073</td>\n",
       "      <td>61.2125</td>\n",
       "      <td>-2388.8030</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>80.4885</td>\n",
       "      <td>116.6789</td>\n",
       "      <td>11.4182</td>\n",
       "      <td>67.631366</td>\n",
       "      <td>710.8212</td>\n",
       "      <td>252.21419</td>\n",
       "      <td>12.853900</td>\n",
       "      <td>217.0388</td>\n",
       "      <td>268.6292</td>\n",
       "      <td>1657.2364</td>\n",
       "      <td>342.3079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10230490.0</td>\n",
       "      <td>2763167.0</td>\n",
       "      <td>5372959.0</td>\n",
       "      <td>5372208.0</td>\n",
       "      <td>2323.876629</td>\n",
       "      <td>0.020667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1992</td>\n",
       "      <td>14.7237</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>196.5341</td>\n",
       "      <td>686.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.712073</td>\n",
       "      <td>53.3170</td>\n",
       "      <td>-2388.8030</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>80.7692</td>\n",
       "      <td>126.1721</td>\n",
       "      <td>9.2752</td>\n",
       "      <td>67.631366</td>\n",
       "      <td>743.6751</td>\n",
       "      <td>252.21419</td>\n",
       "      <td>13.492900</td>\n",
       "      <td>222.1156</td>\n",
       "      <td>264.7898</td>\n",
       "      <td>1653.5068</td>\n",
       "      <td>349.1224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10995568.0</td>\n",
       "      <td>2985663.0</td>\n",
       "      <td>6028494.0</td>\n",
       "      <td>6028939.0</td>\n",
       "      <td>2356.304229</td>\n",
       "      <td>-0.259583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1993</td>\n",
       "      <td>14.7237</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>230.8175</td>\n",
       "      <td>686.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.712073</td>\n",
       "      <td>54.3617</td>\n",
       "      <td>-2388.8030</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>85.0678</td>\n",
       "      <td>81.4607</td>\n",
       "      <td>9.0635</td>\n",
       "      <td>67.631366</td>\n",
       "      <td>791.9246</td>\n",
       "      <td>252.21419</td>\n",
       "      <td>14.055900</td>\n",
       "      <td>201.2057</td>\n",
       "      <td>261.7221</td>\n",
       "      <td>1642.9623</td>\n",
       "      <td>352.2947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11858090.0</td>\n",
       "      <td>3237009.0</td>\n",
       "      <td>7003641.0</td>\n",
       "      <td>7000119.0</td>\n",
       "      <td>2368.470529</td>\n",
       "      <td>0.101917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1994</td>\n",
       "      <td>14.7237</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>242.0494</td>\n",
       "      <td>705.6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.712073</td>\n",
       "      <td>53.9874</td>\n",
       "      <td>-2388.8030</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>88.8058</td>\n",
       "      <td>90.4008</td>\n",
       "      <td>8.3962</td>\n",
       "      <td>67.631366</td>\n",
       "      <td>831.9181</td>\n",
       "      <td>252.21419</td>\n",
       "      <td>15.126900</td>\n",
       "      <td>182.2905</td>\n",
       "      <td>267.6219</td>\n",
       "      <td>1689.3593</td>\n",
       "      <td>367.6784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12690115.0</td>\n",
       "      <td>3482604.0</td>\n",
       "      <td>7733458.0</td>\n",
       "      <td>7722096.0</td>\n",
       "      <td>2500.768729</td>\n",
       "      <td>0.372250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6960</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2016</td>\n",
       "      <td>1190.0089</td>\n",
       "      <td>232.5068</td>\n",
       "      <td>70.9451</td>\n",
       "      <td>7.4088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>251.1465</td>\n",
       "      <td>76500.2982</td>\n",
       "      <td>10662.4408</td>\n",
       "      <td>251.2681</td>\n",
       "      <td>443.0872</td>\n",
       "      <td>428.4352</td>\n",
       "      <td>22.910800</td>\n",
       "      <td>1077.2392</td>\n",
       "      <td>317.07440</td>\n",
       "      <td>2585.080847</td>\n",
       "      <td>858.9820</td>\n",
       "      <td>96.1332</td>\n",
       "      <td>2721.1459</td>\n",
       "      <td>282.5994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>417.3150</td>\n",
       "      <td>10934468.0</td>\n",
       "      <td>5215894.0</td>\n",
       "      <td>6796658.0</td>\n",
       "      <td>7656047.0</td>\n",
       "      <td>98491.026347</td>\n",
       "      <td>1.120250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6961</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2017</td>\n",
       "      <td>1431.1407</td>\n",
       "      <td>131.1324</td>\n",
       "      <td>108.6262</td>\n",
       "      <td>7.9458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>255.7975</td>\n",
       "      <td>76500.2982</td>\n",
       "      <td>10662.4408</td>\n",
       "      <td>203.1236</td>\n",
       "      <td>445.3881</td>\n",
       "      <td>304.7852</td>\n",
       "      <td>18.985700</td>\n",
       "      <td>1093.3441</td>\n",
       "      <td>332.77590</td>\n",
       "      <td>1227.240253</td>\n",
       "      <td>889.4250</td>\n",
       "      <td>81.2314</td>\n",
       "      <td>2744.8763</td>\n",
       "      <td>255.5900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>398.1644</td>\n",
       "      <td>11201138.0</td>\n",
       "      <td>5328766.0</td>\n",
       "      <td>6940631.0</td>\n",
       "      <td>7810471.0</td>\n",
       "      <td>97159.311553</td>\n",
       "      <td>0.046500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6962</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2018</td>\n",
       "      <td>1557.5830</td>\n",
       "      <td>221.6222</td>\n",
       "      <td>109.9835</td>\n",
       "      <td>8.1399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>327.0897</td>\n",
       "      <td>76500.2982</td>\n",
       "      <td>10662.4408</td>\n",
       "      <td>211.1539</td>\n",
       "      <td>492.8599</td>\n",
       "      <td>346.8512</td>\n",
       "      <td>19.057000</td>\n",
       "      <td>1108.5523</td>\n",
       "      <td>348.51070</td>\n",
       "      <td>1127.687805</td>\n",
       "      <td>966.2650</td>\n",
       "      <td>81.0712</td>\n",
       "      <td>2790.0949</td>\n",
       "      <td>257.2735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>465.7735</td>\n",
       "      <td>11465748.0</td>\n",
       "      <td>5447513.0</td>\n",
       "      <td>7086002.0</td>\n",
       "      <td>7966181.0</td>\n",
       "      <td>97668.308205</td>\n",
       "      <td>0.516333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6963</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2019</td>\n",
       "      <td>1591.6049</td>\n",
       "      <td>171.0262</td>\n",
       "      <td>45.4574</td>\n",
       "      <td>7.8322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>290.1893</td>\n",
       "      <td>76500.2982</td>\n",
       "      <td>10662.4408</td>\n",
       "      <td>228.6381</td>\n",
       "      <td>542.5922</td>\n",
       "      <td>350.2168</td>\n",
       "      <td>17.951400</td>\n",
       "      <td>1121.3255</td>\n",
       "      <td>327.82090</td>\n",
       "      <td>2485.528399</td>\n",
       "      <td>945.9420</td>\n",
       "      <td>85.7211</td>\n",
       "      <td>2828.7215</td>\n",
       "      <td>267.5224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>444.2335</td>\n",
       "      <td>11725970.0</td>\n",
       "      <td>5571525.0</td>\n",
       "      <td>7231989.0</td>\n",
       "      <td>8122618.0</td>\n",
       "      <td>98988.062799</td>\n",
       "      <td>0.985667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6964</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2020</td>\n",
       "      <td>481.9027</td>\n",
       "      <td>48.4197</td>\n",
       "      <td>108.3022</td>\n",
       "      <td>7.9733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>238.7639</td>\n",
       "      <td>76500.2982</td>\n",
       "      <td>10662.4408</td>\n",
       "      <td>213.9211</td>\n",
       "      <td>568.0445</td>\n",
       "      <td>350.2168</td>\n",
       "      <td>16.675400</td>\n",
       "      <td>1134.1634</td>\n",
       "      <td>307.41450</td>\n",
       "      <td>1227.240253</td>\n",
       "      <td>940.4200</td>\n",
       "      <td>85.3143</td>\n",
       "      <td>2829.7457</td>\n",
       "      <td>266.7316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>444.2335</td>\n",
       "      <td>11980005.0</td>\n",
       "      <td>5700460.0</td>\n",
       "      <td>7385220.0</td>\n",
       "      <td>8284447.0</td>\n",
       "      <td>96505.221853</td>\n",
       "      <td>0.189000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6965 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Area  Year  Savanna fires  Forest fires  Crop Residues  \\\n",
       "0     Afghanistan  1990        14.7237        0.0557       205.6077   \n",
       "1     Afghanistan  1991        14.7237        0.0557       209.4971   \n",
       "2     Afghanistan  1992        14.7237        0.0557       196.5341   \n",
       "3     Afghanistan  1993        14.7237        0.0557       230.8175   \n",
       "4     Afghanistan  1994        14.7237        0.0557       242.0494   \n",
       "...           ...   ...            ...           ...            ...   \n",
       "6960     Zimbabwe  2016      1190.0089      232.5068        70.9451   \n",
       "6961     Zimbabwe  2017      1431.1407      131.1324       108.6262   \n",
       "6962     Zimbabwe  2018      1557.5830      221.6222       109.9835   \n",
       "6963     Zimbabwe  2019      1591.6049      171.0262        45.4574   \n",
       "6964     Zimbabwe  2020       481.9027       48.4197       108.3022   \n",
       "\n",
       "      Rice Cultivation  Drained organic soils (CO2)  Pesticides Manufacturing  \\\n",
       "0             686.0000                          0.0                 11.807483   \n",
       "1             678.1600                          0.0                 11.712073   \n",
       "2             686.0000                          0.0                 11.712073   \n",
       "3             686.0000                          0.0                 11.712073   \n",
       "4             705.6000                          0.0                 11.712073   \n",
       "...                ...                          ...                       ...   \n",
       "6960            7.4088                          0.0                 75.000000   \n",
       "6961            7.9458                          0.0                 67.000000   \n",
       "6962            8.1399                          0.0                 66.000000   \n",
       "6963            7.8322                          0.0                 73.000000   \n",
       "6964            7.9733                          0.0                 73.000000   \n",
       "\n",
       "      Food Transport  Forestland  Net Forest conversion  \\\n",
       "0            63.1152  -2388.8030                 0.0000   \n",
       "1            61.2125  -2388.8030                 0.0000   \n",
       "2            53.3170  -2388.8030                 0.0000   \n",
       "3            54.3617  -2388.8030                 0.0000   \n",
       "4            53.9874  -2388.8030                 0.0000   \n",
       "...              ...         ...                    ...   \n",
       "6960        251.1465  76500.2982             10662.4408   \n",
       "6961        255.7975  76500.2982             10662.4408   \n",
       "6962        327.0897  76500.2982             10662.4408   \n",
       "6963        290.1893  76500.2982             10662.4408   \n",
       "6964        238.7639  76500.2982             10662.4408   \n",
       "\n",
       "      Food Household Consumption  Food Retail  On-farm Electricity Use  \\\n",
       "0                        79.0851     109.6446                  14.2666   \n",
       "1                        80.4885     116.6789                  11.4182   \n",
       "2                        80.7692     126.1721                   9.2752   \n",
       "3                        85.0678      81.4607                   9.0635   \n",
       "4                        88.8058      90.4008                   8.3962   \n",
       "...                          ...          ...                      ...   \n",
       "6960                    251.2681     443.0872                 428.4352   \n",
       "6961                    203.1236     445.3881                 304.7852   \n",
       "6962                    211.1539     492.8599                 346.8512   \n",
       "6963                    228.6381     542.5922                 350.2168   \n",
       "6964                    213.9211     568.0445                 350.2168   \n",
       "\n",
       "      Food Packaging  Agrifood Systems Waste Disposal  Food Processing  \\\n",
       "0          67.631366                         691.7888        252.21419   \n",
       "1          67.631366                         710.8212        252.21419   \n",
       "2          67.631366                         743.6751        252.21419   \n",
       "3          67.631366                         791.9246        252.21419   \n",
       "4          67.631366                         831.9181        252.21419   \n",
       "...              ...                              ...              ...   \n",
       "6960       22.910800                        1077.2392        317.07440   \n",
       "6961       18.985700                        1093.3441        332.77590   \n",
       "6962       19.057000                        1108.5523        348.51070   \n",
       "6963       17.951400                        1121.3255        327.82090   \n",
       "6964       16.675400                        1134.1634        307.41450   \n",
       "\n",
       "      Fertilizers Manufacturing      IPPU  Manure applied to Soils  \\\n",
       "0                     11.997000  209.9778                 260.1431   \n",
       "1                     12.853900  217.0388                 268.6292   \n",
       "2                     13.492900  222.1156                 264.7898   \n",
       "3                     14.055900  201.2057                 261.7221   \n",
       "4                     15.126900  182.2905                 267.6219   \n",
       "...                         ...       ...                      ...   \n",
       "6960                2585.080847  858.9820                  96.1332   \n",
       "6961                1227.240253  889.4250                  81.2314   \n",
       "6962                1127.687805  966.2650                  81.0712   \n",
       "6963                2485.528399  945.9420                  85.7211   \n",
       "6964                1227.240253  940.4200                  85.3143   \n",
       "\n",
       "      Manure left on Pasture  Manure Management  Fires in organic soils  \\\n",
       "0                  1590.5319           319.1763                     0.0   \n",
       "1                  1657.2364           342.3079                     0.0   \n",
       "2                  1653.5068           349.1224                     0.0   \n",
       "3                  1642.9623           352.2947                     0.0   \n",
       "4                  1689.3593           367.6784                     0.0   \n",
       "...                      ...                ...                     ...   \n",
       "6960               2721.1459           282.5994                     0.0   \n",
       "6961               2744.8763           255.5900                     0.0   \n",
       "6962               2790.0949           257.2735                     0.0   \n",
       "6963               2828.7215           267.5224                     0.0   \n",
       "6964               2829.7457           266.7316                     0.0   \n",
       "\n",
       "      Fires in humid tropical forests  On-farm energy use  Rural population  \\\n",
       "0                                 0.0                 NaN         9655167.0   \n",
       "1                                 0.0                 NaN        10230490.0   \n",
       "2                                 0.0                 NaN        10995568.0   \n",
       "3                                 0.0                 NaN        11858090.0   \n",
       "4                                 0.0                 NaN        12690115.0   \n",
       "...                               ...                 ...               ...   \n",
       "6960                              0.0            417.3150        10934468.0   \n",
       "6961                              0.0            398.1644        11201138.0   \n",
       "6962                              0.0            465.7735        11465748.0   \n",
       "6963                              0.0            444.2335        11725970.0   \n",
       "6964                              0.0            444.2335        11980005.0   \n",
       "\n",
       "      Urban population  Total Population - Male  Total Population - Female  \\\n",
       "0            2593947.0                5348387.0                  5346409.0   \n",
       "1            2763167.0                5372959.0                  5372208.0   \n",
       "2            2985663.0                6028494.0                  6028939.0   \n",
       "3            3237009.0                7003641.0                  7000119.0   \n",
       "4            3482604.0                7733458.0                  7722096.0   \n",
       "...                ...                      ...                        ...   \n",
       "6960         5215894.0                6796658.0                  7656047.0   \n",
       "6961         5328766.0                6940631.0                  7810471.0   \n",
       "6962         5447513.0                7086002.0                  7966181.0   \n",
       "6963         5571525.0                7231989.0                  8122618.0   \n",
       "6964         5700460.0                7385220.0                  8284447.0   \n",
       "\n",
       "      total_emission  Average Temperature °C  \n",
       "0        2198.963539                0.536167  \n",
       "1        2323.876629                0.020667  \n",
       "2        2356.304229               -0.259583  \n",
       "3        2368.470529                0.101917  \n",
       "4        2500.768729                0.372250  \n",
       "...              ...                     ...  \n",
       "6960    98491.026347                1.120250  \n",
       "6961    97159.311553                0.046500  \n",
       "6962    97668.308205                0.516333  \n",
       "6963    98988.062799                0.985667  \n",
       "6964    96505.221853                0.189000  \n",
       "\n",
       "[6965 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displays information on the dataset that  will be used to train the model\n",
    "df.info()\n",
    "# displays unlimited number of columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b707d280",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning <a class=\"anchor\" id=\"chapter4\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4f91fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "# df.isnull().sum()\n",
    "\n",
    "# duplicated rows - none\n",
    "# df.duplicated().sum()\n",
    "\n",
    "\n",
    "#Please use code cells to code in and do not forget to comment your code.\n",
    "df_copy = df.copy()\n",
    "df_copy.shape\n",
    "df_copy.info()\n",
    "\n",
    "\n",
    "# Data Cleaning\n",
    "def check_null_values(df_copy):\n",
    "    \"\"\"\n",
    "    Print the count of null values for each column in a DataFrame.\n",
    "\n",
    "    This function iterates through each column in the DataFrame to check for the presence of null values.\n",
    "    If a column contains null values, it prints the column name along with the number of null values.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The pandas DataFrame to check for null values.\n",
    "\n",
    "    Returns:\n",
    "    None: This function does not return a value; it only prints information.\n",
    "    \"\"\"\n",
    "    for column in df_copy:\n",
    "        if df_copy[column].isnull().any():\n",
    "            print('{0} has {1} null values'.format(column, df_copy[column].isnull().sum()))\n",
    "\n",
    "# run null check\n",
    "check_null_values(df_copy)\n",
    "#check dup\n",
    "def count_duplicate_rows(df_copy):\n",
    "    \"\"\"\n",
    "    Count the number of duplicate rows in a DataFrame.\n",
    "\n",
    "    This function calculates the total number of duplicate rows in the DataFrame by calling the `duplicated` method,\n",
    "    which marks duplicates as `True`, and then sums these cases.\n",
    "\n",
    "    Parameters:\n",
    "    df_copy (pandas.DataFrame): The DataFrame to check for duplicates.\n",
    "\n",
    "    Returns:\n",
    "    int: The count of duplicate rows.\n",
    "    \"\"\"\n",
    "    duplicate_count = df_copy.duplicated().sum()\n",
    "    if duplicate_count == 0:\n",
    "        print(\"No duplicated rows found\")\n",
    "        return 0  # explicitly return 0 instead of relying on implicit return\n",
    "    else:\n",
    "        return duplicate_count\n",
    "\n",
    "\n",
    "# run dup check func\n",
    "count_duplicate_rows(df_copy)\n",
    "\n",
    "# Check for conditional values \n",
    "def check_for_conditional_values(df_copy, condition, value):\n",
    "    \"\"\"\n",
    "     This function replace the \"-1\" values with \"nan\" \n",
    "     so that pandas can use statistical functions accurately on the columns.\n",
    "    \"\"\"\n",
    "    print(f\"Checking columns with values {condition} {value}\")\n",
    "    for col in df_copy.columns:\n",
    "        if df_copy[col].dtype in [\"float64\", \"int64\"]:\n",
    "            if condition == \"<\":\n",
    "                matching_values = df_copy[col] < value\n",
    "            elif condition == \"<=\":\n",
    "                matching_values = df_copy[col] <= value\n",
    "            elif condition == \"==\":\n",
    "                matching_values = df_copy[col] == value\n",
    "            elif condition == \">=\":\n",
    "                matching_values = df_copy[col] >= value\n",
    "            elif condition == \">\":\n",
    "                matching_values = df_copy[col] > value\n",
    "            else:\n",
    "                print(\"Invalid conditional operator specified\")\n",
    "                return\n",
    "            # print(matching_values)\n",
    "            count_matches = matching_values.sum()\n",
    "        \n",
    "            if count_matches > 0:\n",
    "                print(f\"{col} has {count_matches} values matching condition {condition} {value}\")\n",
    "            else:\n",
    "                pass\n",
    "                # print(f\"{col} has no values matching condition {condition} {value}\")\n",
    "\n",
    "#check_for_conditional_values(df, \"<\", 0)\n",
    "\n",
    "check_for_conditional_values(df_copy, \"==\", -1)\n",
    "# replace -1 with nan\n",
    "\n",
    "df_copy.replace(-1, np.nan, inplace=True)\n",
    "\n",
    "# run the check for null values again, now that all the -1 values have been updated to nan\n",
    "check_null_values(df_copy)\n",
    "\n",
    "# examine the datatypes of the columns\n",
    "df_copy.info()\n",
    "\n",
    "# Look for columns that are categorical\n",
    "categorical_columns = df_copy.select_dtypes(include=['object', 'category'])\n",
    "print(categorical_columns)\n",
    "\n",
    "# Print unique values in the \"Date\" column\n",
    "print(df_copy[\"Date\"].unique())\n",
    "\n",
    "# Print the number of unique values in the \"Date\" column\n",
    "print(df_copy[\"Date\"].nunique())\n",
    "\n",
    "# Print the value counts for the \"Date\" column\n",
    "print(df_copy[\"Date\"].value_counts())\n",
    "\n",
    "# Print the number of unique values in the \"type\" column\n",
    "var_type = df_copy[\"type\"].nunique()\n",
    "print(f\"Distinct type count: {var_type}\")\n",
    "\n",
    "# Print the number of unique values in the \"region\" column\n",
    "var_region = df_copy[\"region\"].nunique()\n",
    "print(f\"Distinct region count: {var_region}\")\n",
    "\n",
    "# Get unique values, number of unique values, and value counts for a specific column\n",
    "unique_values = df_copy[\"region\"].unique()\n",
    "nunique_values = df_copy[\"region\"].nunique()\n",
    "value_counts = df_copy[\"region\"].value_counts()\n",
    "\n",
    "print(f\"Unique values: {unique_values}\")\n",
    "print(f\"Number of unique values: {nunique_values}\")\n",
    "print(f\"Value counts:\\n{value_counts}\")\n",
    "\n",
    "\n",
    "# look for columns that are numerical\n",
    "df_copy.select_dtypes(include=['int64'])\n",
    "df_copy.select_dtypes(include=['float64'])\n",
    "\n",
    "\n",
    "# check for negative one, < -1, 0\n",
    "\n",
    "# check_for_negative values(d_copy, \"<\", 0)\n",
    "\n",
    "def check_for_negative_values(df_copy):\n",
    "    \"\"\"\n",
    "    This function checks for negative values in a pandas DataFrame\n",
    "    so that pandas can use statistical functions accurately on the columns.\n",
    "    \"\"\"\n",
    "    for col in df_copy.select_dtypes(include=[\"float64\", \"int64\"]):\n",
    "        negative_values = df_copy[col] < 0\n",
    "        count_negatives = negative_values.sum()\n",
    "        \n",
    "        if count_negatives > 0:\n",
    "            print(f\"{col} has {count_negatives} negative values\")\n",
    "        else:\n",
    "            print(f\"{col} has no negative values\")\n",
    "            return  # return if no negative values are found\n",
    "\n",
    "# Run negative values check\n",
    "check_for_negative_values(df_copy)\n",
    "\n",
    "# Convert the \"Date\" column to datetime format\n",
    "df_copy[\"Date\"] = pd.to_datetime(df_copy[\"Date\"])\n",
    "\n",
    "# Get unique years from the \"Date\" column\n",
    "years = df_copy[\"Date\"].dt.year.unique()\n",
    "\n",
    "# Print the number of unique years\n",
    "print(f\"Number of Years: {len(years)}\")\n",
    "\n",
    "# Print the minimum and maximum years\n",
    "print(f\"Min year: {min(years)}\")\n",
    "print(f\"Max year: {max(years)}\")\n",
    "\n",
    "# Print the range of years\n",
    "print(f\"Check years: {max(years) - min(years)}\")\n",
    "\n",
    "\n",
    "# copy to a new data file\n",
    "df_copy.to_csv('HassAvocadoBoard_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ef3c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_conditional_values(df, condition, value):\n",
    "    '''\n",
    "    Display the number of values in each column that matches the provided condition and value.\n",
    "    Used to identify columns that contain unexpected values e.g. -1 values where the value should be nan \n",
    "    e.g check_for_conditional_values(df, \"==\", -1 ) will print number of records containing \"-1\"\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame to check for duplicate rows.\n",
    "    condition:  The condition or operator to be used \"<\", \"<=\", \"==\", \">=\", or \">\" are valid\n",
    "    value: The value to be used with the condition. Any integer can be used.\n",
    "\n",
    "    Returns:\n",
    "    No return value. The count of values matching the expression per column is printed to the screen.\n",
    "    \"e.g\n",
    "    '''\n",
    "    print(f\"Checking columns with values {condition} {value}\")\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in [\"float64\", \"int64\"]:\n",
    "            if condition == \"<\":\n",
    "                matching_values = df[col] < value\n",
    "            elif condition == \"<=\":\n",
    "                matching_values = df[col] <= value\n",
    "            elif condition == \"==\":\n",
    "                matching_values = df[col] == value\n",
    "            elif condition == \">=\":\n",
    "                matching_values = df[col] >= value\n",
    "            elif condition == \">\":\n",
    "                matching_values = df[col] > value\n",
    "            else:\n",
    "                print(\"Invalid conditional operator specified\")\n",
    "                return\n",
    "            # print(matching_values)\n",
    "            count_matches = matching_values.sum()\n",
    "        \n",
    "            if count_matches > 0:\n",
    "                print(f\"{col} has {count_matches} values matching condition {condition} {value}\")\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "626bf4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking columns with values == -1\n"
     ]
    }
   ],
   "source": [
    "# looking for negative values, nan, -1, 0 values\n",
    "\n",
    "# check_for_conditional_values(df, \"<\", 0)\n",
    "# check_for_conditional_values(df, \"==\", -1)\n",
    "# check_for_conditional_values(df, \"==\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7d681e",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis <a class=\"anchor\" id=\"chapter5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae75afc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "573a8bff",
   "metadata": {},
   "source": [
    "## 6. Regression Models <a class=\"anchor\" id=\"chapter6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b69286",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model comparisons, evaluations, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2101d28",
   "metadata": {},
   "source": [
    "## 7. Conclusion <a class=\"anchor\" id=\"chapter7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b866dd43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
